{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (run this first)\n",
        "!pip install -q librosa resampy soundfile numpy pandas scikit-learn matplotlib tensorflow tqdm\n",
        "print(\"✅ Installed audio + ML libraries\")\n"
      ],
      "metadata": {
        "id": "s2ySzxfvMQ3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2f4174-196f-49fc-a36e-4c44d32310a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Installed audio + ML libraries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "# For modeling\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Ensure reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "ug0QNYrDS6Hr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset folders\n",
        "os.makedirs(\"/content/dataset/calm\", exist_ok=True)\n",
        "os.makedirs(\"/content/dataset/angry\", exist_ok=True)\n",
        "os.makedirs(\"/content/dataset/fearful\", exist_ok=True)\n",
        "\n",
        "print(\"Dataset folders ensured at /content/dataset/{calm,angry,fearful}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkMLREOnTDPA",
        "outputId": "0e92f35e-97d2-4c2a-f095-ef488f82a634"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset folders ensured at /content/dataset/{calm,angry,fearful}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"/content/Audio_Song_Actors_01-24.zip\"\n",
        "if os.path.exists(zip_path):\n",
        "    extract_to = \"/content/RAVDESS\"\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(extract_to)\n",
        "    print(\"✅ Unzipped RAVDESS to /content/RAVDESS\")\n",
        "else:\n",
        "    print(\"No RAVDESS zip file found at /content. Skipping unzip.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgZlWebTJwF",
        "outputId": "3c9b0f6a-f6e8-434b-fef0-c25954c5e032"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No RAVDESS zip file found at /content. Skipping unzip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, glob, os\n",
        "\n",
        "# Create target folders if not exist\n",
        "for folder in [\"calm\", \"angry\", \"fearful\"]:\n",
        "    os.makedirs(f\"/content/dataset/{folder}\", exist_ok=True)\n",
        "\n",
        "moved = 0\n",
        "for file in glob.glob(\"/content/RAVDESS/**/*.wav\", recursive=True):\n",
        "    fname = os.path.basename(file)\n",
        "    parts = fname.split(\"-\")\n",
        "\n",
        "    if len(parts) >= 3:\n",
        "        code = parts[2]\n",
        "        target_folder = None\n",
        "\n",
        "        if code == \"02\":\n",
        "            target_folder = \"calm\"\n",
        "        elif code == \"05\":\n",
        "            target_folder = \"angry\"\n",
        "        elif code == \"06\":\n",
        "            target_folder = \"fearful\"\n",
        "\n",
        "        if target_folder:\n",
        "            dest_path = f\"/content/dataset/{target_folder}/{fname}\"\n",
        "            # Skip if already exists\n",
        "            if not os.path.exists(dest_path):\n",
        "                shutil.copy(file, dest_path)\n",
        "                moved += 1\n",
        "\n",
        "print(f\"✅ Copied {moved} new files (duplicates skipped safely).\")\n",
        "\n",
        "# Display final count in each folder\n",
        "for folder in [\"calm\", \"angry\", \"fearful\"]:\n",
        "    count = len(os.listdir(f\"/content/dataset/{folder}\"))\n",
        "    print(f\"{folder}: {count} files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ZPHnrTWdi_",
        "outputId": "0c333476-46d9-416a-e384-ffb71b3a7607"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Copied 0 new files (duplicates skipped safely).\n",
            "calm: 8 files\n",
            "angry: 8 files\n",
            "fearful: 8 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extraction - consistent across train/predict\n",
        "def extract_features(file_path, n_mfcc=40, n_chroma=12, n_mels=40):\n",
        "    try:\n",
        "        # librosa.load uses resampy internally; installed above.\n",
        "        y, sr = librosa.load(file_path, sr=None)  # sr=None preserves original sampling rate\n",
        "        # MFCC\n",
        "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "        # Chroma\n",
        "        stft = np.abs(librosa.stft(y)) if len(y) > 1 else np.abs(np.array([y]))\n",
        "        chroma = librosa.feature.chroma_stft(S=stft, sr=sr, n_chroma=n_chroma)\n",
        "        chroma_mean = np.mean(chroma.T, axis=0)\n",
        "        # Mel Spectrogram\n",
        "        mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "        mel_mean = np.mean(mel.T, axis=0)\n",
        "        # Combine into one vector\n",
        "        feature_vector = np.hstack([mfccs_mean, chroma_mean, mel_mean])\n",
        "        return feature_vector\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "PsQSUZ45YDZw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from files in the three folders\n",
        "features = []\n",
        "labels = []\n",
        "label_map = {'calm':0, 'angry':1, 'fearful':2}\n",
        "\n",
        "for emotion in ['calm','angry','fearful']:\n",
        "    folder = f\"/content/dataset/{emotion}\"\n",
        "    files = sorted([f for f in os.listdir(folder) if f.lower().endswith('.wav')])\n",
        "    print(f\"Processing {len(files)} files in {emotion}...\")\n",
        "    for f in files:\n",
        "        fp = os.path.join(folder, f)\n",
        "        fv = extract_features(fp)\n",
        "        if fv is not None:\n",
        "            features.append(fv)\n",
        "            labels.append(label_map[emotion])\n",
        "\n",
        "# Convert to arrays\n",
        "X = np.array(features)\n",
        "y = np.array(labels)\n",
        "print(\"Extraction done. Feature shape:\", X.shape)\n",
        "\n",
        "# Save to CSV for reuse\n",
        "if X.size > 0:\n",
        "    df = pd.DataFrame(X)\n",
        "    df['label'] = y\n",
        "    csv_path = \"/content/features.csv\"\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"✅ features.csv saved to {csv_path} (rows: {df.shape[0]}, cols: {df.shape[1]})\")\n",
        "else:\n",
        "    print(\"⚠️ No features extracted. Check your dataset folders; they might be empty.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXXQyYamYMKb",
        "outputId": "be3440ff-20f8-43c7-f406-a47197696b7d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 8 files in calm...\n",
            "Processing 8 files in angry...\n",
            "Processing 8 files in fearful...\n",
            "Extraction done. Feature shape: (24, 92)\n",
            "✅ features.csv saved to /content/features.csv (rows: 24, cols: 93)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If features.csv exists, load it (otherwise use X,y from above)\n",
        "csv_path = \"/content/features.csv\"\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    X = df.drop('label', axis=1).values\n",
        "    y = df['label'].values\n",
        "    print(\"Loaded features.csv\")\n",
        "else:\n",
        "    print(\"No features.csv found; using in-memory extracted arrays.\")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Save scaler for later use\n",
        "import joblib\n",
        "joblib.dump(scaler, \"/content/scaler.save\")\n",
        "\n",
        "# Train/test split (stratify to keep class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Train samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nujZ0Ic3YPAf",
        "outputId": "bf3d520b-b757-46b3-b2e9-be55c388c967"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded features.csv\n",
            "Train samples: 19, Test samples: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[1]\n",
        "num_classes = 3\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(num_features,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=16)\n",
        "# Save model\n",
        "model.save('/content/stress_emotion_model.h5')\n",
        "print(\"✅ Model trained and saved to /content/stress_emotion_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-oyDoD6NYZkS",
        "outputId": "b06e5ccf-ce75-488c-fb0a-549439e9baf0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m23,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,155\u001b[0m (254.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,155</span> (254.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,155\u001b[0m (254.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,155</span> (254.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 232ms/step - accuracy: 0.2029 - loss: 1.2335 - val_accuracy: 0.6000 - val_loss: 0.9178\n",
            "Epoch 2/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6502 - loss: 0.8477 - val_accuracy: 0.8000 - val_loss: 0.7898\n",
            "Epoch 3/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5175 - loss: 0.8291 - val_accuracy: 0.8000 - val_loss: 0.6913\n",
            "Epoch 4/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8531 - loss: 0.5085 - val_accuracy: 0.8000 - val_loss: 0.5982\n",
            "Epoch 5/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9090 - loss: 0.4847 - val_accuracy: 1.0000 - val_loss: 0.5085\n",
            "Epoch 6/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8882 - loss: 0.4502 - val_accuracy: 1.0000 - val_loss: 0.4345\n",
            "Epoch 7/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9441 - loss: 0.3043 - val_accuracy: 1.0000 - val_loss: 0.3703\n",
            "Epoch 8/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8882 - loss: 0.3344 - val_accuracy: 1.0000 - val_loss: 0.3195\n",
            "Epoch 9/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9441 - loss: 0.2718 - val_accuracy: 1.0000 - val_loss: 0.2765\n",
            "Epoch 10/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.1745 - val_accuracy: 1.0000 - val_loss: 0.2394\n",
            "Epoch 11/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8882 - loss: 0.2436 - val_accuracy: 1.0000 - val_loss: 0.2106\n",
            "Epoch 12/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9441 - loss: 0.1403 - val_accuracy: 1.0000 - val_loss: 0.1873\n",
            "Epoch 13/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9441 - loss: 0.1613 - val_accuracy: 1.0000 - val_loss: 0.1672\n",
            "Epoch 14/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.1377 - val_accuracy: 1.0000 - val_loss: 0.1484\n",
            "Epoch 15/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0929 - val_accuracy: 1.0000 - val_loss: 0.1324\n",
            "Epoch 16/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0896 - val_accuracy: 1.0000 - val_loss: 0.1179\n",
            "Epoch 17/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0554 - val_accuracy: 1.0000 - val_loss: 0.1056\n",
            "Epoch 18/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0546 - val_accuracy: 1.0000 - val_loss: 0.0952\n",
            "Epoch 19/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0346 - val_accuracy: 1.0000 - val_loss: 0.0864\n",
            "Epoch 20/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0382 - val_accuracy: 1.0000 - val_loss: 0.0787\n",
            "Epoch 21/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0934 - val_accuracy: 1.0000 - val_loss: 0.0708\n",
            "Epoch 22/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0316 - val_accuracy: 1.0000 - val_loss: 0.0642\n",
            "Epoch 23/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0328 - val_accuracy: 1.0000 - val_loss: 0.0590\n",
            "Epoch 24/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0360 - val_accuracy: 1.0000 - val_loss: 0.0551\n",
            "Epoch 25/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0303 - val_accuracy: 1.0000 - val_loss: 0.0518\n",
            "Epoch 26/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0196 - val_accuracy: 1.0000 - val_loss: 0.0491\n",
            "Epoch 27/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 1.0000 - val_loss: 0.0467\n",
            "Epoch 28/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0133 - val_accuracy: 1.0000 - val_loss: 0.0445\n",
            "Epoch 29/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0693 - val_accuracy: 1.0000 - val_loss: 0.0423\n",
            "Epoch 30/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 1.0000 - val_loss: 0.0403\n",
            "Epoch 31/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0385\n",
            "Epoch 32/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
            "Epoch 33/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
            "Epoch 34/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0345\n",
            "Epoch 35/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0336\n",
            "Epoch 36/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
            "Epoch 37/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 1.0000 - val_loss: 0.0313\n",
            "Epoch 38/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0304\n",
            "Epoch 39/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
            "Epoch 40/40\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model trained and saved to /content/stress_emotion_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate and show classification report\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {acc*100:.2f}%   Test loss: {loss:.4f}\")\n",
        "\n",
        "# Predictions\n",
        "y_pred_probs = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['calm','angry','fearful']))\n",
        "\n",
        "print(\"Confusion matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUoAifGEYeGp",
        "outputId": "77787d30-5cec-4966-d12b-706d9a4a5b7d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 100.00%   Test loss: 0.0287\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        calm       1.00      1.00      1.00         1\n",
            "       angry       1.00      1.00      1.00         2\n",
            "     fearful       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n",
            "Confusion matrix:\n",
            "[[1 0 0]\n",
            " [0 2 0]\n",
            " [0 0 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell provides a simple file-upload UI and prediction output\n",
        "from google.colab import files\n",
        "import joblib\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "uploaded = files.upload()\n",
        "if len(uploaded) == 0:\n",
        "    print(\"No file uploaded.\")\n",
        "else:\n",
        "    # take the first uploaded file\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    print(\"Uploaded:\", fname)\n",
        "    # Extract features for this file\n",
        "    fv = extract_features(fname)\n",
        "    if fv is None:\n",
        "        print(\"Feature extraction failed for the uploaded file.\")\n",
        "    else:\n",
        "        # Load scaler and model (if not in memory)\n",
        "        scaler = joblib.load(\"/content/scaler.save\")\n",
        "        model = load_model(\"/content/stress_emotion_model.h5\")\n",
        "        fv_scaled = scaler.transform(fv.reshape(1, -1))\n",
        "        probs = model.predict(fv_scaled)[0]  # softmax probabilities\n",
        "        labels = ['calm','angry','fearful']\n",
        "        top_idx = np.argmax(probs)\n",
        "        top_label = labels[top_idx]\n",
        "        top_conf = probs[top_idx]\n",
        "        # Binary stressed/not: angry or fearful -> Stressed\n",
        "        stress_map = { 'calm': 'Not Stressed', 'angry': 'Stressed', 'fearful': 'Stressed' }\n",
        "        stress_decision = stress_map[top_label]\n",
        "        # Print nicely\n",
        "        display(Markdown(f\"### Prediction result for **{fname}**\"))\n",
        "        display(Markdown(f\"**Predicted Emotion:** `{top_label}`  \\n**Confidence:** `{top_conf*100:.2f}%`  \\n**Stress Verdict:** `{stress_decision}`\"))\n",
        "        # Also display full probabilities\n",
        "        prob_text = \"\\n\".join([f\"{labels[i]}: {probs[i]*100:.2f}%\" for i in range(len(labels))])\n",
        "        display(Markdown(f\"**All class probabilities:**\\n{prob_text}\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "kCWHfcZaYinF",
        "outputId": "9c947e49-8c39-4e43-8f9a-f51062ae8f4f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b6143ccb-b1b0-4f98-9c09-4968a6cf2254\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b6143ccb-b1b0-4f98-9c09-4968a6cf2254\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 03-02-02-01-01-02-13.wav to 03-02-02-01-01-02-13.wav\n",
            "Uploaded: 03-02-02-01-01-02-13.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e8b6acfc9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Prediction result for **03-02-02-01-01-02-13.wav**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Predicted Emotion:** `fearful`  \n**Confidence:** `100.00%`  \n**Stress Verdict:** `Stressed`"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**All class probabilities:**\ncalm: 0.00%\nangry: 0.00%\nfearful: 100.00%"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcWS1M_5YrTi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}